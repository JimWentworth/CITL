<!DOCTYPE html>
<html lang="en">
<head>
<meta charset="UTF-8" />
<title>Hands-On Introduction to Generative AI – Verification & Confidence</title>
<meta name="viewport" content="width=device-width, initial-scale=1" />
<style>
  body {
    font-family: system-ui, sans-serif;
    max-width: 900px;
    margin: 0 auto;
    padding: 30px 20px 80px;
    line-height: 1.6;
    color: #13294b;
    background: #fff;
  }
  .banner {
    background: #13294b;
    color: white;
    padding: 14px 20px;
    text-align: center;
    font-size: 1.3rem;
    border-radius: 6px;
    margin-bottom: 28px;
  }
  .step {
    margin-top: 28px;
    padding: 18px;
    border-left: 4px solid #e84a27;
    background: #f8f8f9;
    border-radius: 6px;
  }
  .callout {
    background: #f1f1f4;
    border-left: 4px solid #e84a27;
    padding: 18px;
    border-radius: 6px;
    margin-top: 24px;
  }
  ul {
    margin-top: 10px;
  }
  .example {
    background: #ffffff;
    border: 1px solid #d0d4da;
    border-radius: 12px;
    padding: 16px;
    margin-top: 14px;
  }
  details {
    margin-top: 14px;
    padding: 14px;
    background: #ffffff;
    border: 1px solid #d0d4da;
    border-radius: 6px;
  }
  details summary {
    font-weight: 600;
    cursor: pointer;
    color: #13294b;
  }
  .footer {
    margin-top: 50px;
    padding-top: 14px;
    border-top: 1px solid #d0d4da;
    font-size: 0.85rem;
    text-align: center;
    color: #555;
  }
</style>
</head>

<body>

<div class="banner">
  Hands-On Introduction to Generative AI
</div>

<h1>Verification & Confidence: Knowing When AI Is “Good Enough”</h1>

<p>
  Generative AI often produces fluent, confident responses that appear trustworthy at first
  glance. The challenge for educators and students is not deciding whether AI is “right” or
  “wrong,” but determining <em>how confident they need to be</em> before using an AI-generated
  output.
</p>

<div class="step">
  <h2>Confidence Is Contextual</h2>

  <p>
    AI output exists on a spectrum of reliability. Whether an answer is “good enough” depends
    on the stakes of the task, not the quality of the writing alone.
  </p>

  <p>
    A brainstorming idea does not require the same level of verification as a factual claim,
    a citation, or a policy recommendation.
  </p>
</div>

<div class="step">
  <h2>A Practical Three-Level Model</h2>

  <ul>
    <li>
      <strong>Low-stakes use:</strong> brainstorming, outlining, idea generation, exploratory drafts
    </li>
    <li>
      <strong>Medium-stakes use:</strong> explanations, summaries, teaching materials, study aids
    </li>
    <li>
      <strong>High-stakes use:</strong> factual claims, citations, grading decisions, policy or research outputs
    </li>
  </ul>

  <p>
    As stakes increase, so should the level of verification.
  </p>
</div>

<div class="step">
  <h2>What Verification Looks Like at Each Level</h2>

  <div class="example">
    <strong>Low stakes:</strong><br>
    Ask: “Is this useful or generative?”<br>
    Minimal checking; focus on creativity and direction.
  </div>

  <div class="example">
    <strong>Medium stakes:</strong><br>
    Ask: “Does this align with course materials or known sources?”<br>
    Spot-check key claims; compare with trusted references.
  </div>

  <div class="example">
    <strong>High stakes:</strong><br>
    Ask: “Can I independently verify every important claim?”<br>
    Require sources, cross-check facts, and revise or discard unsupported content.
  </div>
</div>

<div class="callout">
  <strong>Key idea:</strong> Fluent language is not evidence. Confidence should come from
  verification, not from how convincing the output sounds.
</div>

<div class="step">
  <h2>Common Red Flags That Signal the Need to Verify</h2>

  <ul>
    <li>Highly confident tone without sources</li>
    <li>Specific statistics or citations you don’t recognize</li>
    <li>Claims that seem to perfectly confirm expectations</li>
    <li>Vague references to “studies” or “experts”</li>
  </ul>
</div>

<div class="step">
  <h2>Teaching Students to Make These Judgments</h2>

  <p>
    Helping students decide when AI output is “good enough” is a core literacy skill.
    Rather than banning AI or assuming its correctness, instructors can:
  </p>

  <ul>
    <li>Explicitly label tasks as low-, medium-, or high-stakes</li>
    <li>Model verification strategies in class</li>
    <li>Ask students to justify how much checking they performed and why</li>
  </ul>
</div>

<div class="wrapup">
  <h2>Conceptual Wrap-Up</h2>

  <p>
    Verification is not an all-or-nothing activity. It is a judgment calibrated to purpose,
    audience, and consequence.
  </p>

  <details>
    <summary>Show Expanded Explanation</summary>

    <p>
      Generative AI systems are designed to produce plausible language, not guaranteed truth.
      This makes them powerful tools for exploration and drafting, but unreliable as sole
      authorities.
    </p>

    <p>
      Teaching users to scale their trust based on stakes builds durable skills that remain
      relevant as AI tools continue to evolve.
    </p>
  </details>
</div>

<div class="wrapup">
  <details>
    <summary>Practical Guidance for Teaching and Academic Work</summary>

    <p>
      Be explicit with students about which assignments require full verification and which
      allow exploratory use.
    </p>

    <p>
      Encourage students to treat AI output as a starting point, not a final answer.
    </p>

    <p>
      Reward transparent verification practices rather than punishing AI use itself.
    </p>
  </details>
</div>

<div class="footer">
  Generated with AI assistance for the Center for Innovation in Teaching & Learning — Updated January 2026
</div>

</body>
</html>
