Purpose: Introduce limitations + safety

:::

Risks and Safeguards When Using AI

AI is powerful, but it also has predictable failure modes.
Knowing them helps you avoid misuse.

Common Risks
1. Hallucinations (Confident Wrong Answers)

AI will generate false information in a fluent, authoritative tone.
Always verify unfamiliar claims.

2. Bias and Representation

AI reflects patterns in its training data — including stereotypes and gaps.

3. Overreliance

It’s easy to outsource thinking, which can weaken understanding.

4. Privacy Risks

Sharing sensitive information with AI systems can create security concerns.

Safeguards

Verify important information using trusted sources

Provide context so AI makes fewer assumptions

Use iterative questioning to test the output

Avoid sharing private data in prompts or uploads

Check for missing perspectives or overlooked options

When Not to Use AI

Avoid using AI for:

medical, legal, financial, or safety-critical decisions

confidential or proprietary data

evaluating students or employees

generating deceptive content

When in doubt, ask whether a human expert should be involved.
:::